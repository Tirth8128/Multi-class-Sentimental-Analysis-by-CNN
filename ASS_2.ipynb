{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASS-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZ-SKnmSUR-",
        "colab_type": "code",
        "outputId": "cb5d76be-b2ae-477f-80df-f3051262ebea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#importing all the required libraries\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)\n",
        "import nltk \n",
        "import random \n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzgCW0E6SZQe",
        "colab_type": "code",
        "outputId": "fcb00bc5-7421-4e98-82f1-160aafe9fe10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#importing dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/train.tsv',delimiter='\\t',encoding='utf-8')\n",
        "df.head()\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDU5qDu_Sbj2",
        "colab_type": "code",
        "outputId": "374f99bb-4a20-47bc-8b5e-b7ded0ee366a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22044</td>\n",
              "      <td>989</td>\n",
              "      <td>the director , Tom Dey , had spliced together ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>148279</td>\n",
              "      <td>8069</td>\n",
              "      <td>rated EEE for excitement</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37860</td>\n",
              "      <td>1800</td>\n",
              "      <td>realistic portrayal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37115</td>\n",
              "      <td>1759</td>\n",
              "      <td>on the amateurish</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100473</td>\n",
              "      <td>5271</td>\n",
              "      <td>hardest</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0     22044  ...          3\n",
              "1    148279  ...          4\n",
              "2     37860  ...          3\n",
              "3     37115  ...          1\n",
              "4    100473  ...          3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09uWbN4SfNm",
        "colab_type": "code",
        "outputId": "0d7cb1aa-b280-453f-cf29-0ab17df9f00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Spliting the data into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df ['Phrase'], df ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "docs=[]\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "for i in range(len(X_train)):\n",
        "  docs.append([list(word_tokenize(X_train[i])), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  docs.append([list(word_tokenize(X_test[i])), Y_test[i]]) \n",
        "\n",
        "docs[0]"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['clamorous'], 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ccNGN3WvQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data handling \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "\n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wibkp1lHWxuf",
        "colab_type": "code",
        "outputId": "b0790eaa-29a6-4a84-ad0f-247b415396c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepocessing ideas for Textual Feature Extraction\n",
        "for l in range(len(docs)):                   \n",
        "  label = docs[l][1]                         \n",
        "  tmpReview = []                                  \n",
        "  for w in docs[l][0]:                        \n",
        "    newWord = w                                   \n",
        "    if remove_stopwords and (w in stopwords_en):  \n",
        "      continue                                     \n",
        "    if removePuncs and (w in punctuations):       \n",
        "      continue                                   \n",
        "    if useStemming:\n",
        "      newWord = lancaster.stem(newWord)\n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    tmpReview.append(newWord)                     \n",
        "  docs[l] = (tmpReview, label)              \n",
        "  docs[l] = (' '.join(tmpReview), label) \n",
        "\n",
        "print(docs[0])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('clamorous', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InPVUfgzWztX",
        "colab_type": "code",
        "outputId": "35e1f16f-f48a-47f3-e606-7e953c9c07cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.DataFrame(docs, columns=['text', 'sentiment']) \n",
        "df.head()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clamorous</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>appreciated anyone outside under-10 set</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A poignant comedy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trust</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>motivated something franchise possibilities</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          text  sentiment\n",
              "0                                    clamorous          2\n",
              "1      appreciated anyone outside under-10 set          1\n",
              "2                            A poignant comedy          3\n",
              "3                                        trust          2\n",
              "4  motivated something franchise possibilities          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSoEouQN83iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],  df['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gaF2YPvUH7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2000) \n",
        "X = vectorizer.fit_transform(df[\"text\"]) \n",
        "Y = df['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_mDKmY2WSch",
        "colab_type": "code",
        "outputId": "2ab22deb-c392-4940-f19c-b9acfbcfa22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13510     3\n",
              "61932     1\n",
              "82549     2\n",
              "137718    2\n",
              "121990    2\n",
              "         ..\n",
              "94224     3\n",
              "135456    2\n",
              "154729    1\n",
              "23031     2\n",
              "57870     4\n",
              "Name: sentiment, Length: 46818, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvrFic8Uqyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing all the required libraries for the keras model\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzeNFfVU4rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 5\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5AlEWbzSCMP",
        "colab_type": "code",
        "outputId": "c2310715-8686-4222-e228-eb9103e20888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n",
        "# Y_train = to_categorical(Y_train,5)\n",
        "# Y_test = to_categorical(Y_test,5)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBxQFt--fHT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPLB7fDfIQt",
        "colab_type": "code",
        "outputId": "dc322ad0-e1d1-43ca-df04-3676bc064b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ToySXMU87V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying different layers \n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2000,1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Dropout(rate = 0.50))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3I6AgtgMaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXqFVIQiS-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sDSZ7J2ViP8",
        "colab_type": "code",
        "outputId": "7d2ec354-e544-4442-9b07-0b32a4e385c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "model.fit(X_train, Y_train,batch_size=64,epochs=12)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Testing - loss:', score[0])\n",
        "print('Testing - accuracy:', score[1])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "109242/109242 [==============================] - 100s 919us/step - loss: 1.1404 - acc: 0.5551\n",
            "Epoch 2/12\n",
            "109242/109242 [==============================] - 99s 908us/step - loss: 1.0547 - acc: 0.5918\n",
            "Epoch 3/12\n",
            "109242/109242 [==============================] - 102s 936us/step - loss: 1.0332 - acc: 0.6018\n",
            "Epoch 4/12\n",
            "109242/109242 [==============================] - 99s 909us/step - loss: 1.0260 - acc: 0.6054\n",
            "Epoch 5/12\n",
            "109242/109242 [==============================] - 98s 899us/step - loss: 1.0196 - acc: 0.6082\n",
            "Epoch 6/12\n",
            "109242/109242 [==============================] - 100s 916us/step - loss: 1.0151 - acc: 0.6096\n",
            "Epoch 7/12\n",
            "109242/109242 [==============================] - 101s 920us/step - loss: 1.0124 - acc: 0.6109\n",
            "Epoch 8/12\n",
            "109242/109242 [==============================] - 100s 919us/step - loss: 1.0082 - acc: 0.6128\n",
            "Epoch 9/12\n",
            "109242/109242 [==============================] - 98s 896us/step - loss: 1.0051 - acc: 0.6159\n",
            "Epoch 10/12\n",
            "109242/109242 [==============================] - 99s 908us/step - loss: 1.0019 - acc: 0.6167\n",
            "Epoch 11/12\n",
            "109242/109242 [==============================] - 102s 932us/step - loss: 0.9997 - acc: 0.6185\n",
            "Epoch 12/12\n",
            "109242/109242 [==============================] - 99s 906us/step - loss: 0.9989 - acc: 0.6183\n",
            "Testing - loss: 1.0339079383467715\n",
            "Testing - accuracy: 0.6061130334486736\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}